{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "417eeb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Simon\\miniconda3\\envs\\RP\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Finding similar: 100%|██████████| 39032/39032 [03:55<00:00, 165.98it/s]\n",
      "Searching PMIDs:   0%|          | 0/28862 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m get_ipython().run_line_magic(\u001b[33m'\u001b[39m\u001b[33mautoreload\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m2\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mprocess_data\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PubmedQueries\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mPubmedQueries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# process_TAR()\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Simon\\Documents\\Ordner\\Uni\\Master\\25-Sommer\\Research Project\\project-doehl-boolean-clip\\process_data.py:117\u001b[39m, in \u001b[36mPubmedQueries.main\u001b[39m\u001b[34m(self, optional_steps)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m count > \u001b[32m0\u001b[39m:\n\u001b[32m    116\u001b[39m     pmid = record[\u001b[33m\"\u001b[39m\u001b[33mIdList\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[43mcache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtokenized\u001b[49m\u001b[43m]\u001b[49m = record\n\u001b[32m    118\u001b[39m     results.append({\u001b[38;5;28mself\u001b[39m.bool_key: query, \u001b[33m'\u001b[39m\u001b[33mpmid\u001b[39m\u001b[33m'\u001b[39m: pmid})\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i % \u001b[32m100\u001b[39m == \u001b[32m0\u001b[39m:\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# Save updated cache\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: 'NoneType' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from process_data import PubmedQueries\n",
    "\n",
    "PubmedQueries().main()\n",
    "\n",
    "# process_TAR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "86054370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json('data/sysrev.jsonl', lines=True)\n",
    "df['source'] = 'sysrev'\n",
    "df.rename(columns={'title': 'nl_query', 'query': 'bool_query'}, inplace=True)\n",
    "df.to_json('data/sysrev_conv.jsonl', orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f436f4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model: gpt-3.5-turbo-0125\n",
      "Processing model: gpt-3.5-turbo-1106\n",
      "Processing model: gpt-4-1106-preview\n",
      "Processing model: gpt-4o-mini\n",
      "Processing model: HuggingfaceH4\n",
      "Processing model: meta-llama\n",
      "Processing model: mistralai\n",
      "Processing model: o1-2024-12-17\n",
      "Processing model: open-mistral-7b\n",
      "Processing model: open-mixtral-8x7b\n",
      "Processing model: original\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def combine_for_model(md: Path, out_base: Path):\n",
    "    qs = sorted(d for d in md.rglob(\"q*\") if d.is_dir())\n",
    "    if not qs: return\n",
    "    out_base.mkdir(parents=True, exist_ok=True)\n",
    "    out = out_base / md.name\n",
    "\n",
    "    mdf = pd.concat(\n",
    "        ((pd.read_csv(q/\"final_trec_result\"/\"results.rel\", sep=r\"\\s+\", header=None,\n",
    "            names=[\"id\",\"accuracy\",\"f1\",\"f3\",\"recall\"]).assign(prompt_id=q.name))\n",
    "        for q in qs if (q/\"final_trec_result\"/\"results.rel\").exists()), ignore_index=True)\n",
    "    gen = []\n",
    "    for q in qs:\n",
    "        p = q/\"generation_output\"/\"step_0.jsonl\"\n",
    "        if not p.exists(): continue\n",
    "        for line in p.open():\n",
    "            obj = json.loads(line)\n",
    "            obj[\"prompt_id\"] = q.name\n",
    "            obj[\"generated_query\"] = obj[\"existing_prompts\"][\"user\"][1][\"content\"]\n",
    "            del obj[\"existing_prompts\"]\n",
    "            gen.append(obj)\n",
    "    gdf = pd.DataFrame(gen).astype({\"id\": str})\n",
    "    mdf[\"id\"] = mdf[\"id\"].astype(str)\n",
    "\n",
    "    # merge & reorder\n",
    "    df = gdf.merge(mdf, on=[\"prompt_id\",\"id\"], how=\"left\")\n",
    "    cols = [\"id\", \"prompt_id\", \"accuracy\",\"f1\",\"f3\",\"recall\"]\n",
    "    cols += [c for c in df if c not in cols]\n",
    "\n",
    "    # write JSONL\n",
    "    with out.with_suffix(\".jsonl\").open(\"w\", encoding=\"utf-8\") as f:\n",
    "        for rec in df[cols].to_dict(orient=\"records\"):\n",
    "            f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "BASE_DIR = Path(\"data\") / \"result_n_runs\" / \"seed_collection_reproduce\"\n",
    "OUTPUT_DIR = Path(\"data\") / \"combined_outputs\"\n",
    "\n",
    "for model_dir in BASE_DIR.iterdir():\n",
    "    if model_dir.is_dir() and \"Wang\" not in str(model_dir):\n",
    "        print(f\"Processing model: {model_dir.name}\")\n",
    "        combine_for_model(model_dir, OUTPUT_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
