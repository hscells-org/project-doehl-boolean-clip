{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417eeb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from utils.process_data import PubmedQueries\n",
    "\n",
    "PubmedQueries().main()\n",
    "\n",
    "# process_TAR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86054370",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json('data/sysrev.jsonl', lines=True)\n",
    "df['source'] = 'sysrev'\n",
    "df.rename(columns={'title': 'nl_query', 'query': 'bool_query'}, inplace=True)\n",
    "df.to_json('data/sysrev_conv.jsonl', orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f436f4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = Path(\"data\") / \"result_n_runs\" / \"seed_collection_reproduce\"\n",
    "\n",
    "def combine_for_model(out_base: Path):\n",
    "    combined = pd.DataFrame()\n",
    "    out_base.mkdir(parents=True, exist_ok=True)\n",
    "    out = out_base / \"combined_outputs\"\n",
    "    for md in BASE_DIR.iterdir():\n",
    "        if not md.is_dir() or \"Wang\" in str(md): continue\n",
    "        print(f\"Processing model: {md.name}\")\n",
    "\n",
    "        qs = sorted(d for d in md.rglob(\"q*\") if d.is_dir())\n",
    "        if not qs: continue\n",
    "\n",
    "        # Load metric results\n",
    "        mdf = pd.concat(\n",
    "            (pd.read_csv(q / \"final_trec_result\" / \"results.rel\", sep=r\"\\s+\", header=None,\n",
    "                names=[\"id\", \"accuracy\", \"f1\", \"f3\", \"recall\"]).assign(prompt_id=q.name)\n",
    "                for q in qs if (q / \"final_trec_result\" / \"results.rel\").exists() ), ignore_index=True)\n",
    "\n",
    "        # Load generation outputs\n",
    "        gen = []\n",
    "        for q in qs:\n",
    "            p = q / \"generation_output\" / \"step_0.jsonl\"\n",
    "            if not p.exists(): continue\n",
    "            for line in p.open():\n",
    "                obj = json.loads(line)\n",
    "                obj[\"prompt_id\"] = q.name\n",
    "                obj[\"generated_query\"] = obj[\"existing_prompts\"][\"user\"][1][\"content\"]\n",
    "                obj[\"model\"] = md.name\n",
    "                del obj[\"existing_prompts\"]\n",
    "                gen.append(obj)\n",
    "\n",
    "        gdf = pd.DataFrame(gen).astype({\"id\": str})\n",
    "        mdf[\"id\"] = mdf[\"id\"].astype(str)\n",
    "\n",
    "        # Merge and accumulate\n",
    "        df = gdf.merge(mdf, on=[\"prompt_id\", \"id\"], how=\"left\")\n",
    "        combined = pd.concat([combined, df], ignore_index=True)\n",
    "\n",
    "    # Write combined JSONL\n",
    "    cols = [\"id\", \"prompt_id\", \"accuracy\", \"f1\", \"f3\", \"recall\", \"model\"]\n",
    "    cols += [c for c in combined.columns if c not in cols]\n",
    "    with out.with_suffix(\".jsonl\").open(\"w\", encoding=\"utf-8\") as f:\n",
    "        for rec in combined[cols].to_dict(orient=\"records\"):\n",
    "            f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\n",
    "OUTPUT_DIR = Path(\"data\")\n",
    "combine_for_model(OUTPUT_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
