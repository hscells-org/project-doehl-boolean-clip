{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a8f8419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from boolrank import DualSiglip2Model\n",
    "from evaluation import evaluate_on_generated\n",
    "\n",
    "# model = DualSiglip2Model('BAAI/llm-embedder')\n",
    "model = DualSiglip2Model('BAAI/bge-small-en-v1.5')\n",
    "# model = DualSiglip2Model('dmis-lab/biobert-v1.1')\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c981079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1266    0.0000\n",
      "1380    0.0277\n",
      "1283    0.0308\n",
      "1179    0.0314\n",
      "1219    0.0435\n",
      "1322    0.0741\n",
      "1139    0.0856\n",
      "Name: f3, dtype: float64\n",
      "tensor([0.7545, 0.7496, 0.7905, 0.7594, 0.7945, 0.7015, 0.7695],\n",
      "       grad_fn=<ToCopyBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([5, 1, 0, 3, 6, 2, 4])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "\n",
    "group_keys: list[str] = [\"id\", \"model\"]\n",
    "main_name = group_keys[-1]\n",
    "res = defaultdict(lambda: defaultdict(list))\n",
    "df = pd.read_json(\"data/combined_outputs.jsonl\", lines=True)\n",
    "byid = df.sort_values(\"f3\").groupby(group_keys)\n",
    "prompt_data = list(map(lambda tpl: tpl[1], byid))\n",
    "\n",
    "group = prompt_data[0]\n",
    "print(group.f3)\n",
    "logits = model(list(group[\"generated_query\"].values), group[\"topic\"].iloc[0])[\"logits\"]\n",
    "tensor = logits.squeeze().cpu()\n",
    "print(tensor)\n",
    "torch.argsort(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ca6b40",
   "metadata": {},
   "source": [
    "## Untrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5933e029",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluate_on_generated' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mevaluate_on_generated\u001b[49m(model)\n",
      "\u001b[31mNameError\u001b[39m: name 'evaluate_on_generated' is not defined"
     ]
    }
   ],
   "source": [
    "evaluate_on_generated(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "059c6af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating groups: 100%|██████████| 40/40 [00:26<00:00,  1.49it/s]\n",
      "<string>:35: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Average' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "spearman",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pearson",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "f3_variance",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "best_rank",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "e545cb5a-db0e-45db-b37d-45cb043ffe63",
       "rows": [
        [
         "0",
         "1",
         "-0.2038",
         "-0.2442",
         "0.0238",
         "0.0"
        ],
        [
         "1",
         "2",
         "-0.0807",
         "-0.0631",
         "0.028",
         "0.0"
        ],
        [
         "2",
         "3",
         "0.234",
         "0.2122",
         "0.1361",
         "0.5405"
        ],
        [
         "3",
         "4",
         "0.2586",
         "0.293",
         "0.0395",
         "0.5172"
        ],
        [
         "4",
         "6",
         "-0.198",
         "-0.2421",
         "0.0964",
         "0.027"
        ],
        [
         "5",
         "7",
         "-0.348",
         "-0.4912",
         "0.0522",
         "0.5833"
        ],
        [
         "6",
         "8",
         "-0.321",
         "-0.2015",
         "0.038",
         "0.1538"
        ],
        [
         "7",
         "10",
         "0.5156",
         "0.4624",
         "0.1157",
         "0.775"
        ],
        [
         "8",
         "11",
         "0.0023",
         "-0.2777",
         "0.1264",
         "0.8182"
        ],
        [
         "9",
         "12",
         "0.2039",
         "0.194",
         "0.1099",
         "0.0952"
        ],
        [
         "10",
         "13",
         "-0.2694",
         "-0.4102",
         "0.0636",
         "0.1538"
        ],
        [
         "11",
         "14",
         "-0.3516",
         "-0.5468",
         "0.0395",
         "0.4902"
        ],
        [
         "12",
         "15",
         "0.0893",
         "0.0641",
         "0.0625",
         "0.2667"
        ],
        [
         "13",
         "16",
         "-0.0242",
         "0.0597",
         "0.0649",
         "0.8421"
        ],
        [
         "14",
         "17",
         "-0.6501",
         "-0.566",
         "0.1357",
         "0.0263"
        ],
        [
         "15",
         "18",
         "0.2783",
         "0.2763",
         "0.0398",
         "0.7083"
        ],
        [
         "16",
         "22",
         "0.1756",
         "0.1561",
         "0.1418",
         "0.7872"
        ],
        [
         "17",
         "27",
         "-0.4772",
         "-0.5165",
         "0.2109",
         "0.1"
        ],
        [
         "18",
         "32",
         "-0.1898",
         "-0.1299",
         "0.0438",
         "0.7273"
        ],
        [
         "19",
         "39",
         "-0.1129",
         "-0.053",
         "0.1121",
         "0.8148"
        ],
        [
         "20",
         "40",
         "-0.2578",
         "-0.2245",
         "0.0761",
         "0.1"
        ],
        [
         "21",
         "42",
         "-0.5102",
         "-0.3539",
         "0.0097",
         "0.0588"
        ],
        [
         "22",
         "43",
         "-0.114",
         "-0.0553",
         "0.1347",
         "0.1875"
        ],
        [
         "23",
         "44",
         "-0.303",
         "-0.2047",
         "0.1116",
         "0.9796"
        ],
        [
         "24",
         "46",
         "0.2317",
         "0.2315",
         "0.0368",
         "0.814"
        ],
        [
         "25",
         "47",
         "-0.0907",
         "-0.1067",
         "0.0273",
         "0.0588"
        ],
        [
         "26",
         "51",
         "-0.3605",
         "-0.3017",
         "0.0644",
         "0.3077"
        ],
        [
         "27",
         "52",
         "-0.1552",
         "-0.0309",
         "0.0247",
         "0.25"
        ],
        [
         "28",
         "53",
         "-0.2313",
         "-0.267",
         "0.0562",
         "0.1064"
        ],
        [
         "29",
         "60",
         "-0.132",
         "-0.147",
         "0.1299",
         "0.6875"
        ],
        [
         "30",
         "64",
         "-0.2109",
         "-0.2966",
         "0.1191",
         "0.5897"
        ],
        [
         "31",
         "66",
         "0.1537",
         "0.1396",
         "0.016",
         "0.675"
        ],
        [
         "32",
         "67",
         "0.4482",
         "0.3808",
         "0.0628",
         "0.5758"
        ],
        [
         "33",
         "78",
         "-0.4829",
         "-0.5434",
         "0.0336",
         "0.5581"
        ],
        [
         "34",
         "88",
         "-0.3647",
         "-0.4027",
         "0.0512",
         "0.3571"
        ],
        [
         "35",
         "96",
         "0.2456",
         "0.1501",
         "0.1366",
         "0.8056"
        ],
        [
         "36",
         "102",
         "-0.2473",
         "-0.1518",
         "0.073",
         "0.1818"
        ],
        [
         "37",
         "103",
         "0.324",
         "0.3992",
         "0.0514",
         "0.7188"
        ],
        [
         "38",
         "105",
         "0.2326",
         "0.1744",
         "0.0553",
         "0.561"
        ],
        [
         "39",
         "112",
         "-0.3491",
         "-0.1304",
         "0.0302",
         "0.1053"
        ],
        [
         "40",
         "Average",
         "-0.0911",
         "-0.0941",
         "0.0745",
         "0.4276"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 41
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>spearman</th>\n",
       "      <th>pearson</th>\n",
       "      <th>f3_variance</th>\n",
       "      <th>best_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.2038</td>\n",
       "      <td>-0.2442</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.0807</td>\n",
       "      <td>-0.0631</td>\n",
       "      <td>0.0280</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.2340</td>\n",
       "      <td>0.2122</td>\n",
       "      <td>0.1361</td>\n",
       "      <td>0.5405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.2586</td>\n",
       "      <td>0.2930</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.5172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>-0.1980</td>\n",
       "      <td>-0.2421</td>\n",
       "      <td>0.0964</td>\n",
       "      <td>0.0270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.3480</td>\n",
       "      <td>-0.4912</td>\n",
       "      <td>0.0522</td>\n",
       "      <td>0.5833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>-0.3210</td>\n",
       "      <td>-0.2015</td>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.1538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>0.5156</td>\n",
       "      <td>0.4624</td>\n",
       "      <td>0.1157</td>\n",
       "      <td>0.7750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>-0.2777</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>0.8182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12</td>\n",
       "      <td>0.2039</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.0952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13</td>\n",
       "      <td>-0.2694</td>\n",
       "      <td>-0.4102</td>\n",
       "      <td>0.0636</td>\n",
       "      <td>0.1538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14</td>\n",
       "      <td>-0.3516</td>\n",
       "      <td>-0.5468</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.4902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15</td>\n",
       "      <td>0.0893</td>\n",
       "      <td>0.0641</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.2667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16</td>\n",
       "      <td>-0.0242</td>\n",
       "      <td>0.0597</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.8421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>17</td>\n",
       "      <td>-0.6501</td>\n",
       "      <td>-0.5660</td>\n",
       "      <td>0.1357</td>\n",
       "      <td>0.0263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18</td>\n",
       "      <td>0.2783</td>\n",
       "      <td>0.2763</td>\n",
       "      <td>0.0398</td>\n",
       "      <td>0.7083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>22</td>\n",
       "      <td>0.1756</td>\n",
       "      <td>0.1561</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.7872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>27</td>\n",
       "      <td>-0.4772</td>\n",
       "      <td>-0.5165</td>\n",
       "      <td>0.2109</td>\n",
       "      <td>0.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>32</td>\n",
       "      <td>-0.1898</td>\n",
       "      <td>-0.1299</td>\n",
       "      <td>0.0438</td>\n",
       "      <td>0.7273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>39</td>\n",
       "      <td>-0.1129</td>\n",
       "      <td>-0.0530</td>\n",
       "      <td>0.1121</td>\n",
       "      <td>0.8148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>40</td>\n",
       "      <td>-0.2578</td>\n",
       "      <td>-0.2245</td>\n",
       "      <td>0.0761</td>\n",
       "      <td>0.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>42</td>\n",
       "      <td>-0.5102</td>\n",
       "      <td>-0.3539</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>43</td>\n",
       "      <td>-0.1140</td>\n",
       "      <td>-0.0553</td>\n",
       "      <td>0.1347</td>\n",
       "      <td>0.1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>44</td>\n",
       "      <td>-0.3030</td>\n",
       "      <td>-0.2047</td>\n",
       "      <td>0.1116</td>\n",
       "      <td>0.9796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>46</td>\n",
       "      <td>0.2317</td>\n",
       "      <td>0.2315</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.8140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>47</td>\n",
       "      <td>-0.0907</td>\n",
       "      <td>-0.1067</td>\n",
       "      <td>0.0273</td>\n",
       "      <td>0.0588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>51</td>\n",
       "      <td>-0.3605</td>\n",
       "      <td>-0.3017</td>\n",
       "      <td>0.0644</td>\n",
       "      <td>0.3077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>52</td>\n",
       "      <td>-0.1552</td>\n",
       "      <td>-0.0309</td>\n",
       "      <td>0.0247</td>\n",
       "      <td>0.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>53</td>\n",
       "      <td>-0.2313</td>\n",
       "      <td>-0.2670</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.1064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>60</td>\n",
       "      <td>-0.1320</td>\n",
       "      <td>-0.1470</td>\n",
       "      <td>0.1299</td>\n",
       "      <td>0.6875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>64</td>\n",
       "      <td>-0.2109</td>\n",
       "      <td>-0.2966</td>\n",
       "      <td>0.1191</td>\n",
       "      <td>0.5897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>66</td>\n",
       "      <td>0.1537</td>\n",
       "      <td>0.1396</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.6750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>67</td>\n",
       "      <td>0.4482</td>\n",
       "      <td>0.3808</td>\n",
       "      <td>0.0628</td>\n",
       "      <td>0.5758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>78</td>\n",
       "      <td>-0.4829</td>\n",
       "      <td>-0.5434</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.5581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>88</td>\n",
       "      <td>-0.3647</td>\n",
       "      <td>-0.4027</td>\n",
       "      <td>0.0512</td>\n",
       "      <td>0.3571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>96</td>\n",
       "      <td>0.2456</td>\n",
       "      <td>0.1501</td>\n",
       "      <td>0.1366</td>\n",
       "      <td>0.8056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>102</td>\n",
       "      <td>-0.2473</td>\n",
       "      <td>-0.1518</td>\n",
       "      <td>0.0730</td>\n",
       "      <td>0.1818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>103</td>\n",
       "      <td>0.3240</td>\n",
       "      <td>0.3992</td>\n",
       "      <td>0.0514</td>\n",
       "      <td>0.7188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>105</td>\n",
       "      <td>0.2326</td>\n",
       "      <td>0.1744</td>\n",
       "      <td>0.0553</td>\n",
       "      <td>0.5610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>112</td>\n",
       "      <td>-0.3491</td>\n",
       "      <td>-0.1304</td>\n",
       "      <td>0.0302</td>\n",
       "      <td>0.1053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Average</td>\n",
       "      <td>-0.0911</td>\n",
       "      <td>-0.0941</td>\n",
       "      <td>0.0745</td>\n",
       "      <td>0.4276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  spearman  pearson  f3_variance  best_rank\n",
       "0         1   -0.2038  -0.2442       0.0238     0.0000\n",
       "1         2   -0.0807  -0.0631       0.0280     0.0000\n",
       "2         3    0.2340   0.2122       0.1361     0.5405\n",
       "3         4    0.2586   0.2930       0.0395     0.5172\n",
       "4         6   -0.1980  -0.2421       0.0964     0.0270\n",
       "5         7   -0.3480  -0.4912       0.0522     0.5833\n",
       "6         8   -0.3210  -0.2015       0.0380     0.1538\n",
       "7        10    0.5156   0.4624       0.1157     0.7750\n",
       "8        11    0.0023  -0.2777       0.1264     0.8182\n",
       "9        12    0.2039   0.1940       0.1099     0.0952\n",
       "10       13   -0.2694  -0.4102       0.0636     0.1538\n",
       "11       14   -0.3516  -0.5468       0.0395     0.4902\n",
       "12       15    0.0893   0.0641       0.0625     0.2667\n",
       "13       16   -0.0242   0.0597       0.0649     0.8421\n",
       "14       17   -0.6501  -0.5660       0.1357     0.0263\n",
       "15       18    0.2783   0.2763       0.0398     0.7083\n",
       "16       22    0.1756   0.1561       0.1418     0.7872\n",
       "17       27   -0.4772  -0.5165       0.2109     0.1000\n",
       "18       32   -0.1898  -0.1299       0.0438     0.7273\n",
       "19       39   -0.1129  -0.0530       0.1121     0.8148\n",
       "20       40   -0.2578  -0.2245       0.0761     0.1000\n",
       "21       42   -0.5102  -0.3539       0.0097     0.0588\n",
       "22       43   -0.1140  -0.0553       0.1347     0.1875\n",
       "23       44   -0.3030  -0.2047       0.1116     0.9796\n",
       "24       46    0.2317   0.2315       0.0368     0.8140\n",
       "25       47   -0.0907  -0.1067       0.0273     0.0588\n",
       "26       51   -0.3605  -0.3017       0.0644     0.3077\n",
       "27       52   -0.1552  -0.0309       0.0247     0.2500\n",
       "28       53   -0.2313  -0.2670       0.0562     0.1064\n",
       "29       60   -0.1320  -0.1470       0.1299     0.6875\n",
       "30       64   -0.2109  -0.2966       0.1191     0.5897\n",
       "31       66    0.1537   0.1396       0.0160     0.6750\n",
       "32       67    0.4482   0.3808       0.0628     0.5758\n",
       "33       78   -0.4829  -0.5434       0.0336     0.5581\n",
       "34       88   -0.3647  -0.4027       0.0512     0.3571\n",
       "35       96    0.2456   0.1501       0.1366     0.8056\n",
       "36      102   -0.2473  -0.1518       0.0730     0.1818\n",
       "37      103    0.3240   0.3992       0.0514     0.7188\n",
       "38      105    0.2326   0.1744       0.0553     0.5610\n",
       "39      112   -0.3491  -0.1304       0.0302     0.1053\n",
       "40  Average   -0.0911  -0.0941       0.0745     0.4276"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_on_generated(model, [\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d1a427",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff4773e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DualSiglip2Model(\n",
       "  (encoder_bool): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 384, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 384)\n",
       "      (token_type_embeddings): Embedding(2, 384)\n",
       "      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (encoder_text): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 384, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 384)\n",
       "      (token_type_embeddings): Embedding(2, 384)\n",
       "      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load(r\"models\\clip\\bge-small-en-v1.5\\b16_lr1E-05_(pubmed-que_pubmed-sea_raw-jsonl)^4\\checkpoint-11288\\model.safetensors\")\n",
    "# model.load(r\"models\\clip\\biobert-v1.1\\b16_lr1E-05_(pubmed-que_pubmed-sea_raw-jsonl)^4\\checkpoint-14110\\model.safetensors\")\n",
    "evaluate_on_generated(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6de21db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating groups: 100%|██████████| 40/40 [00:28<00:00,  1.40it/s]\n",
      "<string>:34: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Average' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "spearman",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pearson",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "f3_variance",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "a67e7519-b38c-453d-bf5c-a714e4b224ff",
       "rows": [
        [
         "0",
         "1",
         "0.1499",
         "0.1373",
         "0.0238"
        ],
        [
         "1",
         "2",
         "-0.4789",
         "-0.5184",
         "0.028"
        ],
        [
         "2",
         "3",
         "-0.0287",
         "-0.0319",
         "0.1361"
        ],
        [
         "3",
         "4",
         "-0.1227",
         "0.1435",
         "0.0395"
        ],
        [
         "4",
         "6",
         "0.1769",
         "0.1084",
         "0.0964"
        ],
        [
         "5",
         "7",
         "0.1902",
         "0.0789",
         "0.0522"
        ],
        [
         "6",
         "8",
         "0.1651",
         "0.0428",
         "0.038"
        ],
        [
         "7",
         "10",
         "-0.2105",
         "0.1164",
         "0.1157"
        ],
        [
         "8",
         "11",
         "-0.0531",
         "-0.1159",
         "0.1264"
        ],
        [
         "9",
         "12",
         "-0.2714",
         "-0.2478",
         "0.1099"
        ],
        [
         "10",
         "13",
         "-0.2431",
         "-0.42",
         "0.0636"
        ],
        [
         "11",
         "14",
         "-0.2814",
         "-0.4421",
         "0.0395"
        ],
        [
         "12",
         "15",
         "0.3857",
         "0.0834",
         "0.0625"
        ],
        [
         "13",
         "16",
         "0.2292",
         "0.2406",
         "0.0649"
        ],
        [
         "14",
         "17",
         "-0.166",
         "-0.072",
         "0.1357"
        ],
        [
         "15",
         "18",
         "0.1435",
         "0.1941",
         "0.0398"
        ],
        [
         "16",
         "22",
         "0.3722",
         "0.315",
         "0.1418"
        ],
        [
         "17",
         "27",
         "0.0914",
         "0.2245",
         "0.2109"
        ],
        [
         "18",
         "32",
         "0.235",
         "0.1985",
         "0.0438"
        ],
        [
         "19",
         "39",
         "-0.2357",
         "-0.0479",
         "0.1121"
        ],
        [
         "20",
         "40",
         "-0.1479",
         "-0.1021",
         "0.0761"
        ],
        [
         "21",
         "42",
         "-0.394",
         "-0.27",
         "0.0097"
        ],
        [
         "22",
         "43",
         "-0.0957",
         "-0.069",
         "0.1347"
        ],
        [
         "23",
         "44",
         "-0.1933",
         "-0.2453",
         "0.1116"
        ],
        [
         "24",
         "46",
         "0.0806",
         "-0.0519",
         "0.0368"
        ],
        [
         "25",
         "47",
         "0.076",
         "0.2118",
         "0.0273"
        ],
        [
         "26",
         "51",
         "-0.337",
         "-0.6495",
         "0.0644"
        ],
        [
         "27",
         "52",
         "-0.024",
         "0.1076",
         "0.0247"
        ],
        [
         "28",
         "53",
         "0.0382",
         "0.0313",
         "0.0562"
        ],
        [
         "29",
         "60",
         "-0.3035",
         "-0.3259",
         "0.1299"
        ],
        [
         "30",
         "64",
         "0.0107",
         "0.1269",
         "0.1191"
        ],
        [
         "31",
         "66",
         "-0.2398",
         "-0.1122",
         "0.016"
        ],
        [
         "32",
         "67",
         "0.3663",
         "0.3546",
         "0.0628"
        ],
        [
         "33",
         "78",
         "-0.4458",
         "-0.5617",
         "0.0336"
        ],
        [
         "34",
         "88",
         "0.18",
         "0.2015",
         "0.0512"
        ],
        [
         "35",
         "96",
         "0.1511",
         "0.0585",
         "0.1366"
        ],
        [
         "36",
         "102",
         "0.2594",
         "0.2321",
         "0.073"
        ],
        [
         "37",
         "103",
         "-0.2188",
         "-0.2531",
         "0.0514"
        ],
        [
         "38",
         "105",
         "-0.1909",
         "-0.1292",
         "0.0553"
        ],
        [
         "39",
         "112",
         "-0.6754",
         "-0.5648",
         "0.0302"
        ],
        [
         "40",
         "Average",
         "-0.0514",
         "-0.0506",
         "0.0745"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 41
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>spearman</th>\n",
       "      <th>pearson</th>\n",
       "      <th>f3_variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1499</td>\n",
       "      <td>0.1373</td>\n",
       "      <td>0.0238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.4789</td>\n",
       "      <td>-0.5184</td>\n",
       "      <td>0.0280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.0287</td>\n",
       "      <td>-0.0319</td>\n",
       "      <td>0.1361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.1227</td>\n",
       "      <td>0.1435</td>\n",
       "      <td>0.0395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.1769</td>\n",
       "      <td>0.1084</td>\n",
       "      <td>0.0964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>0.1902</td>\n",
       "      <td>0.0789</td>\n",
       "      <td>0.0522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0.1651</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>-0.2105</td>\n",
       "      <td>0.1164</td>\n",
       "      <td>0.1157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>-0.0531</td>\n",
       "      <td>-0.1159</td>\n",
       "      <td>0.1264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12</td>\n",
       "      <td>-0.2714</td>\n",
       "      <td>-0.2478</td>\n",
       "      <td>0.1099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13</td>\n",
       "      <td>-0.2431</td>\n",
       "      <td>-0.4200</td>\n",
       "      <td>0.0636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14</td>\n",
       "      <td>-0.2814</td>\n",
       "      <td>-0.4421</td>\n",
       "      <td>0.0395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>0.0834</td>\n",
       "      <td>0.0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16</td>\n",
       "      <td>0.2292</td>\n",
       "      <td>0.2406</td>\n",
       "      <td>0.0649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>17</td>\n",
       "      <td>-0.1660</td>\n",
       "      <td>-0.0720</td>\n",
       "      <td>0.1357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18</td>\n",
       "      <td>0.1435</td>\n",
       "      <td>0.1941</td>\n",
       "      <td>0.0398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>22</td>\n",
       "      <td>0.3722</td>\n",
       "      <td>0.3150</td>\n",
       "      <td>0.1418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>27</td>\n",
       "      <td>0.0914</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.2109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>32</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.1985</td>\n",
       "      <td>0.0438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>39</td>\n",
       "      <td>-0.2357</td>\n",
       "      <td>-0.0479</td>\n",
       "      <td>0.1121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>40</td>\n",
       "      <td>-0.1479</td>\n",
       "      <td>-0.1021</td>\n",
       "      <td>0.0761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>42</td>\n",
       "      <td>-0.3940</td>\n",
       "      <td>-0.2700</td>\n",
       "      <td>0.0097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>43</td>\n",
       "      <td>-0.0957</td>\n",
       "      <td>-0.0690</td>\n",
       "      <td>0.1347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>44</td>\n",
       "      <td>-0.1933</td>\n",
       "      <td>-0.2453</td>\n",
       "      <td>0.1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>46</td>\n",
       "      <td>0.0806</td>\n",
       "      <td>-0.0519</td>\n",
       "      <td>0.0368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>47</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.2118</td>\n",
       "      <td>0.0273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>51</td>\n",
       "      <td>-0.3370</td>\n",
       "      <td>-0.6495</td>\n",
       "      <td>0.0644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>52</td>\n",
       "      <td>-0.0240</td>\n",
       "      <td>0.1076</td>\n",
       "      <td>0.0247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>53</td>\n",
       "      <td>0.0382</td>\n",
       "      <td>0.0313</td>\n",
       "      <td>0.0562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>60</td>\n",
       "      <td>-0.3035</td>\n",
       "      <td>-0.3259</td>\n",
       "      <td>0.1299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.1269</td>\n",
       "      <td>0.1191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>66</td>\n",
       "      <td>-0.2398</td>\n",
       "      <td>-0.1122</td>\n",
       "      <td>0.0160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>67</td>\n",
       "      <td>0.3663</td>\n",
       "      <td>0.3546</td>\n",
       "      <td>0.0628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>78</td>\n",
       "      <td>-0.4458</td>\n",
       "      <td>-0.5617</td>\n",
       "      <td>0.0336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>88</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.2015</td>\n",
       "      <td>0.0512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>96</td>\n",
       "      <td>0.1511</td>\n",
       "      <td>0.0585</td>\n",
       "      <td>0.1366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>102</td>\n",
       "      <td>0.2594</td>\n",
       "      <td>0.2321</td>\n",
       "      <td>0.0730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>103</td>\n",
       "      <td>-0.2188</td>\n",
       "      <td>-0.2531</td>\n",
       "      <td>0.0514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>105</td>\n",
       "      <td>-0.1909</td>\n",
       "      <td>-0.1292</td>\n",
       "      <td>0.0553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>112</td>\n",
       "      <td>-0.6754</td>\n",
       "      <td>-0.5648</td>\n",
       "      <td>0.0302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Average</td>\n",
       "      <td>-0.0514</td>\n",
       "      <td>-0.0506</td>\n",
       "      <td>0.0745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  spearman  pearson  f3_variance\n",
       "0         1    0.1499   0.1373       0.0238\n",
       "1         2   -0.4789  -0.5184       0.0280\n",
       "2         3   -0.0287  -0.0319       0.1361\n",
       "3         4   -0.1227   0.1435       0.0395\n",
       "4         6    0.1769   0.1084       0.0964\n",
       "5         7    0.1902   0.0789       0.0522\n",
       "6         8    0.1651   0.0428       0.0380\n",
       "7        10   -0.2105   0.1164       0.1157\n",
       "8        11   -0.0531  -0.1159       0.1264\n",
       "9        12   -0.2714  -0.2478       0.1099\n",
       "10       13   -0.2431  -0.4200       0.0636\n",
       "11       14   -0.2814  -0.4421       0.0395\n",
       "12       15    0.3857   0.0834       0.0625\n",
       "13       16    0.2292   0.2406       0.0649\n",
       "14       17   -0.1660  -0.0720       0.1357\n",
       "15       18    0.1435   0.1941       0.0398\n",
       "16       22    0.3722   0.3150       0.1418\n",
       "17       27    0.0914   0.2245       0.2109\n",
       "18       32    0.2350   0.1985       0.0438\n",
       "19       39   -0.2357  -0.0479       0.1121\n",
       "20       40   -0.1479  -0.1021       0.0761\n",
       "21       42   -0.3940  -0.2700       0.0097\n",
       "22       43   -0.0957  -0.0690       0.1347\n",
       "23       44   -0.1933  -0.2453       0.1116\n",
       "24       46    0.0806  -0.0519       0.0368\n",
       "25       47    0.0760   0.2118       0.0273\n",
       "26       51   -0.3370  -0.6495       0.0644\n",
       "27       52   -0.0240   0.1076       0.0247\n",
       "28       53    0.0382   0.0313       0.0562\n",
       "29       60   -0.3035  -0.3259       0.1299\n",
       "30       64    0.0107   0.1269       0.1191\n",
       "31       66   -0.2398  -0.1122       0.0160\n",
       "32       67    0.3663   0.3546       0.0628\n",
       "33       78   -0.4458  -0.5617       0.0336\n",
       "34       88    0.1800   0.2015       0.0512\n",
       "35       96    0.1511   0.0585       0.1366\n",
       "36      102    0.2594   0.2321       0.0730\n",
       "37      103   -0.2188  -0.2531       0.0514\n",
       "38      105   -0.1909  -0.1292       0.0553\n",
       "39      112   -0.6754  -0.5648       0.0302\n",
       "40  Average   -0.0514  -0.0506       0.0745"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_on_generated(model, [\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6980f973",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "663e548a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DualSiglip2Model(\n",
       "  (encoder_bool): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 384, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 384)\n",
       "      (token_type_embeddings): Embedding(2, 384)\n",
       "      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (encoder_text): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 384, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 384)\n",
       "      (token_type_embeddings): Embedding(2, 384)\n",
       "      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load(r\"models\\clip\\bge-small-en-v1.5\\b16_(pubmed-que_pubmed-sea_raw-jsonl)^4\\checkpoint-11288\\model.safetensors\")\n",
    "# evaluate_on_generated(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f4e1875",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating groups: 100%|██████████| 40/40 [00:27<00:00,  1.46it/s]\n",
      "<string>:34: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Average' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "spearman",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pearson",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "f3_variance",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "6aeac9df-e3b4-41e5-b4c7-4d1bd104ae6f",
       "rows": [
        [
         "0",
         "1",
         "0.0718",
         "0.0138",
         "0.0238"
        ],
        [
         "1",
         "2",
         "-0.3333",
         "-0.3502",
         "0.028"
        ],
        [
         "2",
         "3",
         "0.0702",
         "-0.0122",
         "0.1361"
        ],
        [
         "3",
         "4",
         "0.1197",
         "0.1119",
         "0.0395"
        ],
        [
         "4",
         "6",
         "0.065",
         "0.0671",
         "0.0964"
        ],
        [
         "5",
         "7",
         "-0.1616",
         "-0.4852",
         "0.0522"
        ],
        [
         "6",
         "8",
         "-0.466",
         "-0.2771",
         "0.038"
        ],
        [
         "7",
         "10",
         "0.5062",
         "0.4091",
         "0.1157"
        ],
        [
         "8",
         "11",
         "0.0739",
         "-0.1904",
         "0.1264"
        ],
        [
         "9",
         "12",
         "0.3896",
         "0.4052",
         "0.1099"
        ],
        [
         "10",
         "13",
         "-0.3651",
         "-0.6789",
         "0.0636"
        ],
        [
         "11",
         "14",
         "-0.307",
         "-0.5024",
         "0.0395"
        ],
        [
         "12",
         "15",
         "0.1857",
         "0.1961",
         "0.0625"
        ],
        [
         "13",
         "16",
         "0.0237",
         "0.0952",
         "0.0649"
        ],
        [
         "14",
         "17",
         "-0.3745",
         "-0.232",
         "0.1357"
        ],
        [
         "15",
         "18",
         "0.0348",
         "0.1008",
         "0.0398"
        ],
        [
         "16",
         "22",
         "-0.0415",
         "0.0942",
         "0.1418"
        ],
        [
         "17",
         "27",
         "-0.2494",
         "-0.2526",
         "0.2109"
        ],
        [
         "18",
         "32",
         "0.112",
         "0.1096",
         "0.0438"
        ],
        [
         "19",
         "39",
         "-0.127",
         "-0.0873",
         "0.1121"
        ],
        [
         "20",
         "40",
         "-0.261",
         "-0.2491",
         "0.0761"
        ],
        [
         "21",
         "42",
         "-0.637",
         "-0.5422",
         "0.0097"
        ],
        [
         "22",
         "43",
         "-0.0029",
         "-0.0556",
         "0.1347"
        ],
        [
         "23",
         "44",
         "-0.2",
         "-0.1219",
         "0.1116"
        ],
        [
         "24",
         "46",
         "-0.0625",
         "-0.0803",
         "0.0368"
        ],
        [
         "25",
         "47",
         "-0.0368",
         "0.0989",
         "0.0273"
        ],
        [
         "26",
         "51",
         "-0.4111",
         "-0.4918",
         "0.0644"
        ],
        [
         "27",
         "52",
         "-0.2261",
         "-0.0404",
         "0.0247"
        ],
        [
         "28",
         "53",
         "-0.3935",
         "-0.3823",
         "0.0562"
        ],
        [
         "29",
         "60",
         "-0.0685",
         "-0.1064",
         "0.1299"
        ],
        [
         "30",
         "64",
         "-0.0945",
         "-0.0655",
         "0.1191"
        ],
        [
         "31",
         "66",
         "0.1338",
         "0.0391",
         "0.016"
        ],
        [
         "32",
         "67",
         "0.3563",
         "0.305",
         "0.0628"
        ],
        [
         "33",
         "78",
         "-0.5504",
         "-0.7647",
         "0.0336"
        ],
        [
         "34",
         "88",
         "-0.1921",
         "-0.0888",
         "0.0512"
        ],
        [
         "35",
         "96",
         "0.1117",
         "0.0674",
         "0.1366"
        ],
        [
         "36",
         "102",
         "-0.0334",
         "0.053",
         "0.073"
        ],
        [
         "37",
         "103",
         "-0.0902",
         "0.0192",
         "0.0514"
        ],
        [
         "38",
         "105",
         "0.1857",
         "0.167",
         "0.0553"
        ],
        [
         "39",
         "112",
         "-0.7667",
         "-0.5118",
         "0.0302"
        ],
        [
         "40",
         "Average",
         "-0.1003",
         "-0.1054",
         "0.0745"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 41
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>spearman</th>\n",
       "      <th>pearson</th>\n",
       "      <th>f3_variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0718</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.3333</td>\n",
       "      <td>-0.3502</td>\n",
       "      <td>0.0280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0702</td>\n",
       "      <td>-0.0122</td>\n",
       "      <td>0.1361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.1197</td>\n",
       "      <td>0.1119</td>\n",
       "      <td>0.0395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0650</td>\n",
       "      <td>0.0671</td>\n",
       "      <td>0.0964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.1616</td>\n",
       "      <td>-0.4852</td>\n",
       "      <td>0.0522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>-0.4660</td>\n",
       "      <td>-0.2771</td>\n",
       "      <td>0.0380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>0.5062</td>\n",
       "      <td>0.4091</td>\n",
       "      <td>0.1157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0739</td>\n",
       "      <td>-0.1904</td>\n",
       "      <td>0.1264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12</td>\n",
       "      <td>0.3896</td>\n",
       "      <td>0.4052</td>\n",
       "      <td>0.1099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13</td>\n",
       "      <td>-0.3651</td>\n",
       "      <td>-0.6789</td>\n",
       "      <td>0.0636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14</td>\n",
       "      <td>-0.3070</td>\n",
       "      <td>-0.5024</td>\n",
       "      <td>0.0395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15</td>\n",
       "      <td>0.1857</td>\n",
       "      <td>0.1961</td>\n",
       "      <td>0.0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0237</td>\n",
       "      <td>0.0952</td>\n",
       "      <td>0.0649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>17</td>\n",
       "      <td>-0.3745</td>\n",
       "      <td>-0.2320</td>\n",
       "      <td>0.1357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18</td>\n",
       "      <td>0.0348</td>\n",
       "      <td>0.1008</td>\n",
       "      <td>0.0398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>22</td>\n",
       "      <td>-0.0415</td>\n",
       "      <td>0.0942</td>\n",
       "      <td>0.1418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>27</td>\n",
       "      <td>-0.2494</td>\n",
       "      <td>-0.2526</td>\n",
       "      <td>0.2109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>32</td>\n",
       "      <td>0.1120</td>\n",
       "      <td>0.1096</td>\n",
       "      <td>0.0438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>39</td>\n",
       "      <td>-0.1270</td>\n",
       "      <td>-0.0873</td>\n",
       "      <td>0.1121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>40</td>\n",
       "      <td>-0.2610</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>0.0761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>42</td>\n",
       "      <td>-0.6370</td>\n",
       "      <td>-0.5422</td>\n",
       "      <td>0.0097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>43</td>\n",
       "      <td>-0.0029</td>\n",
       "      <td>-0.0556</td>\n",
       "      <td>0.1347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>44</td>\n",
       "      <td>-0.2000</td>\n",
       "      <td>-0.1219</td>\n",
       "      <td>0.1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>46</td>\n",
       "      <td>-0.0625</td>\n",
       "      <td>-0.0803</td>\n",
       "      <td>0.0368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>47</td>\n",
       "      <td>-0.0368</td>\n",
       "      <td>0.0989</td>\n",
       "      <td>0.0273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>51</td>\n",
       "      <td>-0.4111</td>\n",
       "      <td>-0.4918</td>\n",
       "      <td>0.0644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>52</td>\n",
       "      <td>-0.2261</td>\n",
       "      <td>-0.0404</td>\n",
       "      <td>0.0247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>53</td>\n",
       "      <td>-0.3935</td>\n",
       "      <td>-0.3823</td>\n",
       "      <td>0.0562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>60</td>\n",
       "      <td>-0.0685</td>\n",
       "      <td>-0.1064</td>\n",
       "      <td>0.1299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>64</td>\n",
       "      <td>-0.0945</td>\n",
       "      <td>-0.0655</td>\n",
       "      <td>0.1191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>66</td>\n",
       "      <td>0.1338</td>\n",
       "      <td>0.0391</td>\n",
       "      <td>0.0160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>67</td>\n",
       "      <td>0.3563</td>\n",
       "      <td>0.3050</td>\n",
       "      <td>0.0628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>78</td>\n",
       "      <td>-0.5504</td>\n",
       "      <td>-0.7647</td>\n",
       "      <td>0.0336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>88</td>\n",
       "      <td>-0.1921</td>\n",
       "      <td>-0.0888</td>\n",
       "      <td>0.0512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>96</td>\n",
       "      <td>0.1117</td>\n",
       "      <td>0.0674</td>\n",
       "      <td>0.1366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>102</td>\n",
       "      <td>-0.0334</td>\n",
       "      <td>0.0530</td>\n",
       "      <td>0.0730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>103</td>\n",
       "      <td>-0.0902</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.0514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>105</td>\n",
       "      <td>0.1857</td>\n",
       "      <td>0.1670</td>\n",
       "      <td>0.0553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>112</td>\n",
       "      <td>-0.7667</td>\n",
       "      <td>-0.5118</td>\n",
       "      <td>0.0302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Average</td>\n",
       "      <td>-0.1003</td>\n",
       "      <td>-0.1054</td>\n",
       "      <td>0.0745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  spearman  pearson  f3_variance\n",
       "0         1    0.0718   0.0138       0.0238\n",
       "1         2   -0.3333  -0.3502       0.0280\n",
       "2         3    0.0702  -0.0122       0.1361\n",
       "3         4    0.1197   0.1119       0.0395\n",
       "4         6    0.0650   0.0671       0.0964\n",
       "5         7   -0.1616  -0.4852       0.0522\n",
       "6         8   -0.4660  -0.2771       0.0380\n",
       "7        10    0.5062   0.4091       0.1157\n",
       "8        11    0.0739  -0.1904       0.1264\n",
       "9        12    0.3896   0.4052       0.1099\n",
       "10       13   -0.3651  -0.6789       0.0636\n",
       "11       14   -0.3070  -0.5024       0.0395\n",
       "12       15    0.1857   0.1961       0.0625\n",
       "13       16    0.0237   0.0952       0.0649\n",
       "14       17   -0.3745  -0.2320       0.1357\n",
       "15       18    0.0348   0.1008       0.0398\n",
       "16       22   -0.0415   0.0942       0.1418\n",
       "17       27   -0.2494  -0.2526       0.2109\n",
       "18       32    0.1120   0.1096       0.0438\n",
       "19       39   -0.1270  -0.0873       0.1121\n",
       "20       40   -0.2610  -0.2491       0.0761\n",
       "21       42   -0.6370  -0.5422       0.0097\n",
       "22       43   -0.0029  -0.0556       0.1347\n",
       "23       44   -0.2000  -0.1219       0.1116\n",
       "24       46   -0.0625  -0.0803       0.0368\n",
       "25       47   -0.0368   0.0989       0.0273\n",
       "26       51   -0.4111  -0.4918       0.0644\n",
       "27       52   -0.2261  -0.0404       0.0247\n",
       "28       53   -0.3935  -0.3823       0.0562\n",
       "29       60   -0.0685  -0.1064       0.1299\n",
       "30       64   -0.0945  -0.0655       0.1191\n",
       "31       66    0.1338   0.0391       0.0160\n",
       "32       67    0.3563   0.3050       0.0628\n",
       "33       78   -0.5504  -0.7647       0.0336\n",
       "34       88   -0.1921  -0.0888       0.0512\n",
       "35       96    0.1117   0.0674       0.1366\n",
       "36      102   -0.0334   0.0530       0.0730\n",
       "37      103   -0.0902   0.0192       0.0514\n",
       "38      105    0.1857   0.1670       0.0553\n",
       "39      112   -0.7667  -0.5118       0.0302\n",
       "40  Average   -0.1003  -0.1054       0.0745"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_on_generated(model, [\"id\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
